{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how to scrap imdb top 10000 films and get high quality posters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def main(start):\n",
    "    url = f\"https://www.imdb.com/search/title/?title_type=feature&num_votes=10000,&sort=user_rating,desc&count=100&start={start}&ref_=adv_nxt\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content , \"html.parser\")\n",
    "\n",
    "    movies = []\n",
    "\n",
    "    movies_data = soup.findAll(\"div\" , attrs={\"class\":\"lister-item mode-advanced\"})\n",
    "\n",
    "    for movie in movies_data:\n",
    "        name = movie.h3.a.text\n",
    "        release_year = movie.h3.find(\"span\", class_ = \"lister-item-year text-muted unbold\").text.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        movie_time = movie.p.find(\"span\", class_ = \"runtime\").text.replace(' min', '')\n",
    "        movie_rating = movie.find(\"div\", class_ = \"inline-block ratings-imdb-rating\").text.replace(\"\\n\", \"\")\n",
    "        genre = movie.p.find(\"span\", class_ = \"genre\").text.strip().replace(\"\\n\" , \"\")\n",
    "        description = movie.find_all(\"p\", {\"class\":  \"text-muted\"})[1].text.strip(\"\\n\")\n",
    "        crew = movie.find(\"p\", {\"class\":  \"\"}).find_all(\"a\")\n",
    "        director = crew[0].text\n",
    "        stars = crew[1 : len(crew)]\n",
    "        stars = [star.text for star in stars]\n",
    "        poster = movie.find(\"div\", {\"class\": \"lister-item-image float-left\"}).find(\"img\", \"loadlate\").get('loadlate')\n",
    "    \n",
    "        movies.append({\"name\" : name , \"year\" : release_year ,\n",
    "        \"runtime\" : movie_time ,\"rating\" : movie_rating , \"genre\" : genre , \"image\": poster, \n",
    "        \"description\" : description, \"director\" : director, \"stars\" : stars})\n",
    "\n",
    "    \n",
    "    return json.dumps(movies, indent= 4)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    films = \"\"\n",
    "    for i in range(1, 10001,100):\n",
    "        \n",
    "        films += main(i)\n",
    "        print(f\"done {i}\")\n",
    "    \n",
    "    with open(\"films.json\", \"w\") as f:\n",
    "        f.write(films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a main function that takes a parameter (start) it takes this parameter and requests a hundred film starting from that parameter start\n",
    "first we request the url then we parse the html content with beautiful soup library\n",
    "We then search the content of the page for all divs that has a class of lister-item mode-advanced we only know that it has the data from looking through the page\n",
    "We then iterate over each div in these data\n",
    "Inside each div we will be searching for name, year of release, the run time, the rating, the genre, director, description of the film, the stars and the poster\n",
    "We then transform this to json data and return them \n",
    "After that in our main code we will be iterating from 1 to 10001 and pass that as the main functuion as the start variable\n",
    "after that we write all that json in a file called films.json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could be enough with this however the quality of the poster images are really bad we will be continuing with some more logic to get high quality posters.\n",
    "To get the hd posters we will have to go to each film page specifically and parse that image.\n",
    "First to visit each page dynamcilly we need the specific id for each film that imdb puts on them this can be done easily as it can be found with the data that we parsed before so we will implement the same logic only looking in other place.\n",
    "The code below will get us the 10000 ids and store it in a csv file so we can use it in the next logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def main(start):\n",
    "    url = f\"https://www.imdb.com/search/title/?title_type=feature&num_votes=10000,&sort=user_rating,desc&count=100&start={start}&ref_=adv_nxt\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content , \"html.parser\")\n",
    "\n",
    "    movies = []\n",
    "\n",
    "    movies_data = soup.findAll(\"div\" , attrs={\"class\":\"lister-item mode-advanced\"})\n",
    "\n",
    "    for movie in movies_data:\n",
    "        imdb_id = movie.find(\"div\", class_ = \"lister-item-image float-left\").a[\"href\"]\n",
    "        imdb_id = imdb_id.replace(\"/\", \"\").replace(\"title\", \"\")\n",
    "        movies.append(imdb_id)\n",
    "\n",
    "    return movies  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    films = []\n",
    "    for i in range(1, 10001,100):\n",
    "        films += main(i)\n",
    "        print(f\"done {i}\")\n",
    "    \n",
    "    with open(\"links.csv\", \"w\") as f:\n",
    "        for film in films:\n",
    "            f.write(f'{film}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we write the scrape_link function that takes a url as parameter and requests the page we parse finding the image link and return it.\n",
    "We then write the bigger logic we open the links csv file and then open the films csv file to replace the poster links we read the films and then iterate over them one by one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "import csv\n",
    "import urllib.parse\n",
    "\n",
    "def scrape_link(url):\n",
    "\n",
    "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "    soup = BeautifulSoup(response.content , \"html.parser\")\n",
    "\n",
    "    a = soup.find('a', class_=\"ipc-lockup-overlay ipc-focusable\")\n",
    "\n",
    "    return a[\"href\"]\n",
    "\n",
    "\n",
    "counter = 1\n",
    "\n",
    "\n",
    "with open(\"links.csv\", \"a\") as file:\n",
    "\n",
    "    with open('films.csv', \"r\") as f:\n",
    "        films = f.readlines()\n",
    "\n",
    "    for film in films:\n",
    "        film = film.replace(\"\\n\", \"\")\n",
    "\n",
    "        link = scrape_link(f\"https://www.imdb.com/title/{film}\")\n",
    "\n",
    "        response_2 = requests.get(f\"https://www.imdb.com{link}\", headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        \n",
    "\n",
    "        soup = BeautifulSoup(response_2.content , \"html.parser\")\n",
    "\n",
    "        div = soup.find('div', class_ = \"sc-7c0a9e7c-2 kEDMKk\")\n",
    "        if div:\n",
    "            file.write(f\"{div.img['src']}\\n\")\n",
    "            print(f\"done{counter}\")\n",
    "\n",
    "        else:\n",
    "            file.write(\"\\n\")\n",
    "            print(f\"done{counter} blank\")\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
